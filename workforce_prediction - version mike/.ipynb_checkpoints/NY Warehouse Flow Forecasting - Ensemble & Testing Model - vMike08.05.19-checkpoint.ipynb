{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NY Warehouse Flow Forecasting\n",
    "\n",
    "In this notebook, we tried to predict the inbound & outbound traffic from the warehouse, in order to help allocate workforce. Noted that the max capacity of the warehouse is 3500 orders/day as of July 2019, but our predictions are not limited by that.\n",
    "\n",
    "There are six types of warehouse activities:\n",
    "\n",
    "Outbound customer order\n",
    "Outbound items transfer\n",
    "Outbound purchase order return\n",
    "Inbound customer return\n",
    "Inbound items transfer\n",
    "Inbound purchase order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import queries.utils as utils\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#### bigquery client & credentials\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"C:\\Users\\m.young\\Documents\\BigQueryAPIKey\\modata-79d448dbeef0.json\"\n",
    "client = bigquery.Client()\n",
    "\n",
    "#### fbprophet \n",
    "import fbprophet\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "\n",
    "pd.plotting.register_matplotlib_converters() ## bugs.. fbprophet & matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Actuals Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# data_raw_all = pd.read_csv('data/inven_est_072319.csv')\n",
    "\n",
    "\n",
    "# BQ query\n",
    "wh_actuals_query = \"\"\"\n",
    "SELECT\n",
    "     *\n",
    "FROM adhoc_analytics.project_inven_forecast_actuals_EST\n",
    "  \"\"\"\n",
    "\n",
    "# put query results into pandas df\n",
    "data_raw_all = client.query(wh_actuals_query).to_dataframe()\n",
    "\n",
    "# convert date column to datetime data type\n",
    "data_raw_all['date_est'] = pd.to_datetime(data_raw_all['date_est'])\n",
    "\n",
    "# sort by date desc\n",
    "data_raw_all.sort_values(by='date_est', inplace=True)\n",
    "\n",
    "# reset index numbers after sort\n",
    "data_raw_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# replace NaN with 0s\n",
    "data_raw_all.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Data\n",
    "display(data_raw_all.head())\n",
    "display(data_raw_all.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Excel Predictions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read the current prediction data from the forecast team\n",
    "dat_curr_prediction = pd.read_csv('data/inven_curr_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dat_curr_prediction.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. FB Prophet Holidays Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outbound Customer Orders - Prophet Holidays\n",
    "co_holidays = pd.read_csv('data/co_holidays.csv') # - Copy\n",
    "# add employee sales dates; use promotions date table\n",
    "\n",
    "# Inbound Purchase Orders - Prophet Holidays\n",
    "po_holidays = pd.read_csv('data/po_holidays.csv')\n",
    "\n",
    "# Inbound Customer Returns - Prophet Holidays\n",
    "cr_holidays = pd.read_csv('data/cr_holidays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "display(co_holidays.tail(5))\n",
    "display(po_holidays.tail(5))\n",
    "display(cr_holidays.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Actuals Data for Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outbound - Customer Orders\n",
    "co_dat = data_raw_all[['date_est','OUT_CUST_UNITS']]\n",
    "co_dat = co_dat.rename(columns={'date_est':'ds','OUT_CUST_UNITS':'y'})\n",
    "\n",
    "# Outbound - Vendor Returns\n",
    "vr_dat = data_raw_all[['date_est','OUT_VR_UNITS']]\n",
    "vr_dat = vr_dat.rename(columns={'date_est':'ds','OUT_VR_UNITS':'y'})\n",
    "\n",
    "# Outbound - Transfer Orders\n",
    "oto_dat = data_raw_all[['date_est','OUT_TO_UNITS']]\n",
    "oto_dat = oto_dat.rename(columns={'date_est':'ds','OUT_TO_UNITS':'y'})\n",
    "\n",
    "# Inbound - Customer Returns\n",
    "cr_dat = data_raw_all[['date_est','IN_CUST_UNITS']]\n",
    "cr_dat = cr_dat.rename(columns={'date_est':'ds','IN_CUST_UNITS':'y'})\n",
    "\n",
    "# Inbound - Purchase Orders\n",
    "po_dat = data_raw_all[['date_est','IN_PO_UNITS']]\n",
    "po_dat = po_dat.rename(columns={'date_est':'ds','IN_PO_UNITS':'y'})\n",
    "\n",
    "# Inbound - Transfer Orders\n",
    "ito_dat = data_raw_all[['date_est','IN_TO_UNITS']]\n",
    "ito_dat = ito_dat.rename(columns={'date_est':'ds','IN_TO_UNITS':'y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Forecast Data for Multiple Models Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_curr_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outbound - Customer Orders\n",
    "co_dat_curr_prediction = dat_curr_prediction.loc[:,['FCST_Dt','FCT_OUT_Ord']]\n",
    "co_dat_curr_prediction.rename(columns={'FCST_Dt':'ds','FCT_OUT_Ord':'excel_forecast'},inplace=True)\n",
    "co_dat_curr_prediction.index = pd.to_datetime(co_dat_curr_prediction['ds'])\n",
    "co_dat_curr_prediction.drop([\"ds\"],axis=1,inplace=True)\n",
    "\n",
    "# Outbound - Vendor Returns\n",
    "\n",
    "\n",
    "# Outbound - Transfer Orders\n",
    "oto_dat_curr_prediction = dat_curr_prediction.loc[:,['FCST_Dt','FCT_OUT_TO']]\n",
    "oto_dat_curr_prediction.rename(columns={'FCST_Dt':'ds','FCT_OUT_TO':'excel_forecast'},inplace=True)\n",
    "oto_dat_curr_prediction.index = pd.to_datetime(oto_dat_curr_prediction['ds'])\n",
    "oto_dat_curr_prediction.drop([\"ds\"],axis=1,inplace=True)\n",
    "\n",
    "# Inbound - Customer Returns\n",
    "cr_dat_curr_prediction = dat_curr_prediction.loc[:,['FCST_Dt','FCT_IN_Return']]\n",
    "cr_dat_curr_prediction.rename(columns={'FCST_Dt':'ds','FCT_IN_Return':'excel_forecast'},inplace=True)\n",
    "cr_dat_curr_prediction.index = pd.to_datetime(cr_dat_curr_prediction['ds'])\n",
    "cr_dat_curr_prediction.drop([\"ds\"],axis=1,inplace=True)\n",
    "\n",
    "# Inbound - Purchase Orders\n",
    "po_dat_curr_prediction = dat_curr_prediction.loc[:,['FCST_Dt','FCT_IN_PO']]\n",
    "po_dat_curr_prediction.rename(columns={'FCST_Dt':'ds','FCT_IN_PO':'excel_forecast'},inplace=True)\n",
    "po_dat_curr_prediction.index = pd.to_datetime(po_dat_curr_prediction['ds'])\n",
    "po_dat_curr_prediction.drop([\"ds\"],axis=1,inplace=True)\n",
    "\n",
    "# Inbound - Transfer Orders\n",
    "ito_dat_curr_prediction = dat_curr_prediction.loc[:,['FCST_Dt','FCT_IN_TO']]\n",
    "ito_dat_curr_prediction.rename(columns={'FCST_Dt':'ds','FCT_IN_TO':'excel_forecast'},inplace=True)\n",
    "ito_dat_curr_prediction.index = pd.to_datetime(ito_dat_curr_prediction['ds'])\n",
    "ito_dat_curr_prediction.drop([\"ds\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Train vs Test Datasets for FB Prophet Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Settings\n",
    "split_date = '2019-09-01'  # Setting the train test cutoff date\n",
    "forward_days = 200  # set up how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outbound Customer Orders\n",
    "co_dat_train = co_dat.loc[co_dat.ds<split_date , :]\n",
    "co_dat_test = co_dat.loc[co_dat.ds>=split_date , :]\n",
    "\n",
    "# Outbound - Vendor Returns\n",
    "vr_dat_train = vr_dat.loc[vr_dat.ds<split_date , :]\n",
    "vr_dat_test = vr_dat.loc[vr_dat.ds>=split_date , :]\n",
    "\n",
    "# Outbound - Transfer Orders\n",
    "oto_dat_train = oto_dat.loc[oto_dat.ds<split_date , :]\n",
    "oto_dat_test = oto_dat.loc[oto_dat.ds>=split_date , :]\n",
    "\n",
    "# Inbound - Customer Returns\n",
    "cr_dat_train = cr_dat.loc[cr_dat.ds<split_date , :]\n",
    "cr_dat_test = cr_dat.loc[cr_dat.ds>=split_date , :]\n",
    "\n",
    "# Inbound - Purchase Orders\n",
    "po_dat_train = po_dat.loc[po_dat.ds<split_date , :]\n",
    "po_dat_test = po_dat.loc[po_dat.ds>=split_date , :]\n",
    "\n",
    "# Inbound - Transfer Orders\n",
    "ito_dat_train = ito_dat.loc[ito_dat.ds<split_date , :]\n",
    "ito_dat_test = ito_dat.loc[ito_dat.ds>=split_date , :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outbound Customer Orders\n",
    "co_dat_all = pd.concat([co_dat_train, co_dat_test])\n",
    "\n",
    "# Outbound - Vendor Returns\n",
    "vr_dat_all = pd.concat([vr_dat_train, vr_dat_test])\n",
    "\n",
    "# Outbound - Transfer Orders\n",
    "oto_dat_all = pd.concat([oto_dat_train, oto_dat_test])\n",
    "\n",
    "# Inbound - Customer Returns\n",
    "cr_dat_all = pd.concat([cr_dat_train, cr_dat_test])\n",
    "\n",
    "# Inbound - Purchase Orders\n",
    "po_dat_all = pd.concat([po_dat_train, po_dat_test])\n",
    "\n",
    "# Inbound - Transfer Orders\n",
    "ito_dat_all = pd.concat([ito_dat_train, ito_dat_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbprophet.__version__\n",
    "Prophet = fbprophet.Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. FB Prophet Model - Outbound Customer Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_m = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           ,holidays = co_holidays\n",
    "           )\n",
    "\n",
    "co_m_full = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           ,holidays = co_holidays\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "co_m.fit(co_dat_train)\n",
    "co_m_full.fit(co_dat_all)\n",
    "\n",
    "# predict forward_days \n",
    "co_future = co_m.make_future_dataframe(periods=len(co_dat_test)+forward_days, freq='1D')\n",
    "co_forecast = co_m.predict(co_future)\n",
    "co_forecast.loc[co_forecast.ds>=split_date,:].head()\n",
    "\n",
    "# components showing\n",
    "co_m_full.component_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Validation\n",
    "fig = co_m.plot(co_forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), co_m, co_forecast)\n",
    "\n",
    "\n",
    "f = co_m.plot_components(co_forecast)\n",
    "\n",
    "\n",
    "co_verif = utils.make_verif(co_forecast, co_dat_train, co_dat_test)\n",
    "f = utils.plot_verif(co_verif,date=split_date)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(co_verif, '2019-01-01', '2019-12-31', ax=ax)\n",
    "\n",
    "\n",
    "utils.plot_joint_plot(co_verif.loc[co_verif.index<split_date,:], title='train set', fname=None)\n",
    "\n",
    "utils.plot_joint_plot(co_verif.loc[(co_verif.index>=split_date) &(co_verif['y'].notnull()) ,:], \\\n",
    "                      title='test set', fname=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(co_verif, '2019-05-19', '2019-12-31', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Cross Validation\n",
    "df_cv = cross_validation(co_m_full, initial='1210 days', period='7 days', horizon = '14 days')\n",
    "df_cv_two_week = cross_validation(co_m_full, initial='1210 days', period='1 days', horizon = '14 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv['horizon'] = df_cv['ds']  - df_cv['cutoff']\n",
    "df_cv['mape'] = np.abs(df_cv['yhat'] - df_cv['y'])/ df_cv['y']\n",
    "df_cv = df_cv.loc[df_cv.mape<1,:]\n",
    "df_p = performance_metrics(df_cv, rolling_window=0.1)\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_cross_validation_metric(df_cv, metric='mae')\n",
    "fig = plot_cross_validation_metric(df_cv, metric='mape')\n",
    "fig = plot_cross_validation_metric(df_cv_two_week, metric='mae')\n",
    "fig = plot_cross_validation_metric(df_cv_two_week, metric='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_two_week['horizon'] = df_cv_two_week['ds']  - df_cv_two_week['cutoff']\n",
    "df_two_week_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='14 days',:]\n",
    "df_two_week_prediction.index = df_two_week_prediction.ds\n",
    "df_two_week_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "df_1_day_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='1 days',:]\n",
    "df_1_day_prediction.index = df_1_day_prediction[\"ds\"]\n",
    "df_1_day_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "co_verif_comp = pd.concat([co_dat_curr_prediction, co_verif], axis=1, join='inner').\\\n",
    "filter(items=['yhat_lower','yhat_upper','yhat','y','excel_forecast'])\n",
    "co_verif_comp = co_verif_comp.loc[co_verif_comp['y'].notnull() ,:]\n",
    "co_verif_comp.rename(columns ={'y':'Observations' , 'yhat':f'Prophet Model up until {split_date}', 'excel_forecast':'Current Excel Model'} ,inplace=True)\n",
    "\n",
    "co_verif_comp = co_verif_comp.merge(right = df_two_week_prediction, on=\"ds\" ,how = \"inner\", suffixes=('',\"_2w\"))\n",
    "co_verif_comp.rename(columns ={'yhat':'Prophet Model Two Weeks Ahead'} ,inplace=True)\n",
    "\n",
    "co_verif_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(25,8))\n",
    "co_verif_comp.loc[:,['Observations',f'Prophet Model up until {split_date}'\\\n",
    "                  ,'Current Excel Model','Prophet Model Two Weeks Ahead']].plot(ax=ax)\n",
    "# ax.fill_between(verif_comp.index, verif_comp.loc[:,'yhat_lower'], verif_comp.loc[:,'yhat_upper'], color='coral', alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(co_verif_comp['Current Excel Model'] - co_verif_comp['Observations'])/co_verif_comp['Observations'])))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(co_verif_comp[f'Prophet Model up until {split_date}'] - co_verif_comp['Observations'])/co_verif_comp['Observations'])))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(co_verif_comp['Prophet Model Two Weeks Ahead'] - co_verif_comp['Observations'])/co_verif_comp['Observations'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First (Incorrect 7/23)\n",
    "# MAPE of the Current Model 0.2356932773388679\n",
    "# MAPE of the Prophet Model Up Until 2019-05-19  0.17342342484494647\n",
    "# MAPE of the Prophet Model Two Weeks Prediction  0.16988295234710005\n",
    "\n",
    "# Second (Corrected 7/24)\n",
    "# MAPE of the Current Model 0.2356932773388679\n",
    "# MAPE of the Prophet Model Up Until 2019-05-19  0.17199888077987097\n",
    "# MAPE of the Prophet Model Two Weeks Prediction  0.1686462523082831\n",
    "\n",
    "# Third (w/ Employee)\n",
    "# MAPE of the Current Model 0.2356932773388679\n",
    "# MAPE of the Prophet Model Up Until 2019-05-19  0.17404171412011635\n",
    "# MAPE of the Prophet Model Two Weeks Prediction  0.17068368655718888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(np.abs(co_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - co_verif_comp['Observations'].replace(0, np.nan))/co_verif_comp['Observations'].replace(0, np.nan)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. FB Prophet Model - Inbound Purchase Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITONAL REGRESSOR - Purchase Orders Estimated Delivery Windows\n",
    "po_reg_raw = pd.read_csv('data/PO_EST_ACT_MA.csv')\n",
    "po_reg_1_full = po_reg_raw[['date','IN_PO_EST']]\n",
    "po_reg_1_full = po_reg_1_full.rename(columns={'date':'ds','IN_PO_EST':'reg'})\n",
    "\n",
    "po_reg_1_train = po_reg_1_full[po_reg_1_full['ds']<split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_reg_1_full.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_m = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           ,holidays = po_holidays\n",
    "           )\n",
    "\n",
    "po_m_full = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           ,holidays = po_holidays\n",
    "           )\n",
    "\n",
    "# ### Add extra regressors\n",
    "po_dat_train['reg'] = po_reg_1_train['reg']\n",
    "po_m.add_regressor('reg', prior_scale = 10, mode='multiplicative') \n",
    "\n",
    "po_dat_all['reg'] = po_reg_1_full['reg']\n",
    "po_m_full.add_regressor('reg', prior_scale = 10, mode='multiplicative') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "po_m.fit(po_dat_train)\n",
    "po_m_full.fit(po_dat_all)\n",
    "\n",
    "# predict forward_days \n",
    "po_future = po_m.make_future_dataframe(periods=len(po_dat_test)+forward_days, freq='1D')\n",
    "po_future['reg'] = po_reg_1_full['reg']\n",
    "\n",
    "po_future = po_future[po_future['ds'] < '2020-01-01']\n",
    "\n",
    "po_forecast = po_m.predict(po_future)\n",
    "po_forecast.loc[po_forecast.ds>=split_date,:].head()\n",
    "\n",
    "\n",
    "# components showing\n",
    "po_m_full.component_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_verif = utils.make_verif(po_forecast, po_dat_train, po_dat_test)\n",
    "\n",
    "# if weekend then make it 0\n",
    "po_verif['weekend'] = ((pd.DatetimeIndex(po_verif.index).dayofweek) // 5 == 1).astype(float)\n",
    "po_verif.loc[po_verif['weekend'] > 0.0, 'yhat'] = 0\n",
    "\n",
    "# if negative then make it 0\n",
    "po_verif.loc[po_verif['yhat'] < 0.0, 'yhat'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation\n",
    "fig = po_m.plot(po_forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), po_m, po_forecast)\n",
    "\n",
    "f = po_m.plot_components(po_forecast)\n",
    "\n",
    "f = utils.plot_verif(po_verif,date=split_date)\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(po_verif, '2019-01-01', '2019-12-31', ax=ax)\n",
    "\n",
    "\n",
    "utils.plot_joint_plot(po_verif.loc[po_verif.index<split_date,:], title='train set', fname=None)\n",
    "\n",
    "utils.plot_joint_plot(po_verif.loc[(po_verif.index>=split_date) &(po_verif['y'].notnull()) ,:], \\\n",
    "                      title='test set', fname=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(po_verif, '2017-01-01', '2019-12-31', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Cross Validation\n",
    "df_cv = cross_validation(po_m_full, initial='1210 days', period='7 days', horizon = '14 days')\n",
    "df_cv_two_week = cross_validation(po_m_full, initial='1210 days', period='1 days', horizon = '14 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv['horizon'] = df_cv['ds']  - df_cv['cutoff']\n",
    "df_cv['mape'] = np.abs(df_cv['yhat'] - df_cv['y'])/ df_cv['y']\n",
    "df_cv = df_cv.loc[df_cv.mape<1,:]\n",
    "df_p = performance_metrics(df_cv, rolling_window=0.1)\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_two_week['horizon'] = df_cv_two_week['ds']  - df_cv_two_week['cutoff']\n",
    "df_two_week_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='14 days',:]\n",
    "df_two_week_prediction.index = df_two_week_prediction.ds\n",
    "df_two_week_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "df_1_day_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='1 days',:]\n",
    "df_1_day_prediction.index = df_1_day_prediction[\"ds\"]\n",
    "df_1_day_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "po_verif_comp = pd.concat([po_dat_curr_prediction, po_verif], axis=1, join='inner').\\\n",
    "filter(items=['yhat_lower','yhat_upper','yhat','y','excel_forecast'])\n",
    "po_verif_comp = po_verif_comp.loc[po_verif_comp['y'].notnull() ,:]\n",
    "po_verif_comp.rename(columns ={'y':'Observations' , 'yhat':f'Prophet Model up until {split_date}', 'excel_forecast':'Current Excel Model'} ,inplace=True)\n",
    "\n",
    "po_verif_comp = po_verif_comp.merge(right = df_two_week_prediction, on=\"ds\" ,how = \"inner\", suffixes=('',\"_2w\"))\n",
    "po_verif_comp.rename(columns ={'yhat':'Prophet Model Two Weeks Ahead'} ,inplace=True)\n",
    "\n",
    "\n",
    "# if weekend then make it 0\n",
    "po_verif_comp['weekend'] = ((pd.DatetimeIndex(po_verif_comp.index).dayofweek) // 5 == 1).astype(float)\n",
    "po_verif_comp.loc[po_verif_comp['weekend'] > 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "po_verif_comp.loc[po_verif_comp['weekend'] > 0.0, f'Prophet Model up until {split_date}'] = 0\n",
    "\n",
    "# if negative then make it 0\n",
    "po_verif_comp.loc[po_verif_comp['Prophet Model Two Weeks Ahead'] < 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "po_verif_comp.loc[po_verif_comp[f'Prophet Model up until {split_date}'] < 0.0, f'Prophet Model up until {split_date}'] = 0\n",
    "\n",
    "po_verif_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(25,8))\n",
    "po_verif_comp.loc[:,['Observations',f'Prophet Model up until {split_date}'\\\n",
    "                  ,'Current Excel Model','Prophet Model Two Weeks Ahead']].plot(ax=ax)\n",
    "# ax.fill_between(verif_comp.index, verif_comp.loc[:,'yhat_lower'], verif_comp.loc[:,'yhat_upper'], color='coral', alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(po_verif_comp['Current Excel Model'].replace(0, np.nan) - po_verif_comp['Observations'].replace(0, np.nan))/po_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(po_verif_comp[f'Prophet Model up until {split_date}'].replace(0, np.nan) - po_verif_comp['Observations'].replace(0, np.nan))/po_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(po_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - po_verif_comp['Observations'].replace(0, np.nan))/po_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE of the Current Model 21.34107788721027\n",
    "# MAPE of the Prophet Model Up Until 2019-05-19  26.943743728224433\n",
    "# MAPE of the Prophet Model Two Weeks Prediction  25.942597891870182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(po_verif_comp['Current Excel Model'].replace(0, np.nan) - po_verif_comp['Observations'].replace(0, np.nan)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CHECK FOR OUTLIERS SKEWING MAPE RESULTS\n",
    "(np.abs(po_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - po_verif_comp['Observations'].replace(0, np.nan))/po_verif_comp['Observations'].replace(0, np.nan)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE TOP 3 OUTLIERS SKEWING MAPE RESULTS\n",
    "adj_po_verif_comp = po_verif_comp[~po_verif_comp.index.isin(['2019-06-21','2019-06-25','2019-06-27'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECALCULATE MAPE RESULTS w/o OUTLIERS\n",
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(adj_po_verif_comp['Current Excel Model'].replace(0, np.nan) - adj_po_verif_comp['Observations'].replace(0, np.nan))/adj_po_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(adj_po_verif_comp[f'Prophet Model up until {split_date}'].replace(0, np.nan) - adj_po_verif_comp['Observations'].replace(0, np.nan))/adj_po_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(adj_po_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - adj_po_verif_comp['Observations'].replace(0, np.nan))/adj_po_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. FB Prophet Model - Inbound Customer Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cr_m = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "            ,holidays = cr_holidays\n",
    "            \n",
    "           )\n",
    "\n",
    "cr_m_full = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "            ,holidays = cr_holidays\n",
    "           )\n",
    "\n",
    "# fit the model\n",
    "cr_m.fit(cr_dat_train)\n",
    "cr_m_full.fit(cr_dat_all)\n",
    "\n",
    "# predict forward_days \n",
    "cr_future = cr_m.make_future_dataframe(periods=len(cr_dat_test)+forward_days, freq='1D')\n",
    "\n",
    "# test no weekends - No effect\n",
    "# cr_future = cr_future[pd.DatetimeIndex(cr_future['ds']).dayofweek // 5 != 1]\n",
    "\n",
    "cr_forecast = cr_m.predict(cr_future)\n",
    "cr_forecast.loc[cr_forecast.ds>=split_date,:].head()\n",
    "\n",
    "# components showing\n",
    "cr_m_full.component_modes\n",
    "\n",
    "## Validation\n",
    "fig = cr_m.plot(cr_forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), cr_m, cr_forecast)\n",
    "\n",
    "\n",
    "f = cr_m.plot_components(cr_forecast)\n",
    "\n",
    "\n",
    "cr_verif = utils.make_verif(cr_forecast, cr_dat_train, cr_dat_test)\n",
    "f = utils.plot_verif(cr_verif,date=split_date)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(cr_verif, '2019-01-01', '2019-12-31', ax=ax)\n",
    "\n",
    "\n",
    "utils.plot_joint_plot(cr_verif.loc[cr_verif.index<split_date,:], title='train set', fname=None)\n",
    "\n",
    "utils.plot_joint_plot(cr_verif.loc[(cr_verif.index>=split_date) &(cr_verif['y'].notnull()) ,:], \\\n",
    "                      title='test set', fname=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross Validation\n",
    "df_cv = cross_validation(cr_m_full, initial='1210 days', period='7 days', horizon = '14 days')\n",
    "df_cv_two_week = cross_validation(cr_m_full, initial='1210 days', period='1 days', horizon = '14 days')\n",
    "\n",
    "df_cv['horizon'] = df_cv['ds']  - df_cv['cutoff']\n",
    "df_cv['mape'] = np.abs(df_cv['yhat'] - df_cv['y'])/ df_cv['y']\n",
    "df_cv = df_cv.loc[df_cv.mape<1,:]\n",
    "df_p = performance_metrics(df_cv, rolling_window=0.1)\n",
    "df_p.head()\n",
    "\n",
    "df_cv_two_week['horizon'] = df_cv_two_week['ds']  - df_cv_two_week['cutoff']\n",
    "df_two_week_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='14 days',:]\n",
    "df_two_week_prediction.index = df_two_week_prediction.ds\n",
    "df_two_week_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "df_1_day_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='1 days',:]\n",
    "df_1_day_prediction.index = df_1_day_prediction[\"ds\"]\n",
    "df_1_day_prediction.drop(columns=\"ds\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(cr_verif, '2017-01-01', '2019-12-31', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(cr_verif, '2016-01-01', '2017-01-01', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(cr_verif, '2017-01-01', '2018-01-01', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(cr_verif, '2019-01-01', '2019-12-31', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_verif_comp = pd.concat([cr_dat_curr_prediction, cr_verif], axis=1, join='inner').\\\n",
    "filter(items=['yhat_lower','yhat_upper','yhat','y','excel_forecast'])\n",
    "cr_verif_comp = cr_verif_comp.loc[cr_verif_comp['y'].notnull() ,:]\n",
    "cr_verif_comp.rename(columns ={'y':'Observations' , 'yhat':f'Prophet Model up until {split_date}', 'excel_forecast':'Current Excel Model'} ,inplace=True)\n",
    "\n",
    "cr_verif_comp = cr_verif_comp.merge(right = df_two_week_prediction, on=\"ds\" ,how = \"inner\", suffixes=('',\"_2w\"))\n",
    "cr_verif_comp.rename(columns ={'yhat':'Prophet Model Two Weeks Ahead'} ,inplace=True)\n",
    "\n",
    "# if weekend then make it 0\n",
    "cr_verif_comp['weekend'] = ((pd.DatetimeIndex(cr_verif_comp.index).dayofweek) // 5 == 1).astype(float)\n",
    "cr_verif_comp.loc[cr_verif_comp['weekend'] > 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "cr_verif_comp.loc[cr_verif_comp['weekend'] > 0.0, f'Prophet Model up until {split_date}'] = 0\n",
    "\n",
    "# if negative then make it 0\n",
    "cr_verif_comp.loc[cr_verif_comp['Prophet Model Two Weeks Ahead'] < 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "cr_verif_comp.loc[cr_verif_comp[f'Prophet Model up until {split_date}'] < 0.0, f'Prophet Model up until {split_date}'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(25,8))\n",
    "cr_verif_comp.loc[:,['Observations',f'Prophet Model up until {split_date}'\\\n",
    "                  ,'Current Excel Model','Prophet Model Two Weeks Ahead']].plot(ax=ax)\n",
    "# ax.fill_between(verif_comp.index, verif_comp.loc[:,'yhat_lower'], verif_comp.loc[:,'yhat_upper'], color='coral', alpha=0.3)\n",
    "\n",
    "\n",
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(cr_verif_comp['Current Excel Model'] - cr_verif_comp['Observations'])/cr_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(cr_verif_comp[f'Prophet Model up until {split_date}'] - cr_verif_comp['Observations'])/cr_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(cr_verif_comp['Prophet Model Two Weeks Ahead'] - cr_verif_comp['Observations'])/cr_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CHECK FOR OUTLIERS SKEWING MAPE RESULTS\n",
    "(np.abs(cr_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - cr_verif_comp['Observations'].replace(0, np.nan))/cr_verif_comp['Observations'].replace(0, np.nan)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE TOP 3 OUTLIERS SKEWING MAPE RESULTS\n",
    "adj_cr_verif_comp = cr_verif_comp[~cr_verif_comp.index.isin(['2019-05-27','2019-07-15','2019-06-25'])]\n",
    "\n",
    "# RECALCULATE MAPE RESULTS w/o OUTLIERS\n",
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(adj_cr_verif_comp['Current Excel Model'].replace(0, np.nan) - adj_cr_verif_comp['Observations'].replace(0, np.nan))/adj_cr_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(adj_cr_verif_comp[f'Prophet Model up until {split_date}'].replace(0, np.nan) - adj_cr_verif_comp['Observations'].replace(0, np.nan))/adj_cr_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(adj_cr_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - adj_cr_verif_comp['Observations'].replace(0, np.nan))/adj_cr_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. FB Prophet Model - Inbound Transfer Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ito_m = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           #,holidays = ito_holidays\n",
    "           )\n",
    "\n",
    "ito_m_full = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           #,holidays = ito_holidays\n",
    "           )\n",
    "\n",
    "# fit the model\n",
    "ito_m.fit(ito_dat_train)\n",
    "ito_m_full.fit(ito_dat_all)\n",
    "\n",
    "# predict forward_days \n",
    "ito_future = ito_m.make_future_dataframe(periods=len(ito_dat_test)+forward_days, freq='1D')\n",
    "ito_forecast = ito_m.predict(ito_future)\n",
    "ito_forecast.loc[ito_forecast.ds>=split_date,:].head()\n",
    "\n",
    "# components showing\n",
    "ito_m_full.component_modes\n",
    "\n",
    "## Validation\n",
    "fig = ito_m.plot(ito_forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), ito_m, ito_forecast)\n",
    "\n",
    "\n",
    "f = ito_m.plot_components(ito_forecast)\n",
    "\n",
    "\n",
    "ito_verif = utils.make_verif(ito_forecast, ito_dat_train, ito_dat_test)\n",
    "f = utils.plot_verif(ito_verif,date=split_date)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(ito_verif, '2019-01-01', '2019-12-31', ax=ax)\n",
    "\n",
    "\n",
    "utils.plot_joint_plot(ito_verif.loc[ito_verif.index<split_date,:], title='train set', fname=None)\n",
    "\n",
    "utils.plot_joint_plot(ito_verif.loc[(ito_verif.index>=split_date) &(ito_verif['y'].notnull()) ,:], \\\n",
    "                      title='test set', fname=None)\n",
    "\n",
    "## Cross Validation\n",
    "df_cv = cross_validation(ito_m_full, initial='1210 days', period='7 days', horizon = '14 days')\n",
    "df_cv_two_week = cross_validation(ito_m_full, initial='1210 days', period='1 days', horizon = '14 days')\n",
    "\n",
    "df_cv['horizon'] = df_cv['ds']  - df_cv['cutoff']\n",
    "df_cv['mape'] = np.abs(df_cv['yhat'] - df_cv['y'])/ df_cv['y']\n",
    "df_cv = df_cv.loc[df_cv.mape<1,:]\n",
    "df_p = performance_metrics(df_cv, rolling_window=0.1)\n",
    "df_p.head()\n",
    "\n",
    "df_cv_two_week['horizon'] = df_cv_two_week['ds']  - df_cv_two_week['cutoff']\n",
    "df_two_week_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='14 days',:]\n",
    "df_two_week_prediction.index = df_two_week_prediction.ds\n",
    "df_two_week_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "df_1_day_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='1 days',:]\n",
    "df_1_day_prediction.index = df_1_day_prediction[\"ds\"]\n",
    "df_1_day_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "ito_verif_comp = pd.concat([ito_dat_curr_prediction, ito_verif], axis=1, join='inner').\\\n",
    "filter(items=['yhat_lower','yhat_upper','yhat','y','excel_forecast'])\n",
    "ito_verif_comp = ito_verif_comp.loc[ito_verif_comp['y'].notnull() ,:]\n",
    "ito_verif_comp.rename(columns ={'y':'Observations' , 'yhat':f'Prophet Model up until {split_date}', 'excel_forecast':'Current Excel Model'} ,inplace=True)\n",
    "\n",
    "ito_verif_comp = ito_verif_comp.merge(right = df_two_week_prediction, on=\"ds\" ,how = \"inner\", suffixes=('',\"_2w\"))\n",
    "ito_verif_comp.rename(columns ={'yhat':'Prophet Model Two Weeks Ahead'} ,inplace=True)\n",
    "\n",
    "# if weekend then make it 0\n",
    "ito_verif_comp['weekend'] = ((pd.DatetimeIndex(ito_verif_comp.index).dayofweek) // 5 == 1).astype(float)\n",
    "ito_verif_comp.loc[ito_verif_comp['weekend'] > 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "ito_verif_comp.loc[ito_verif_comp['weekend'] > 0.0, f'Prophet Model up until {split_date}'] = 0\n",
    "\n",
    "# if negative then make it 0\n",
    "ito_verif_comp.loc[ito_verif_comp['Prophet Model Two Weeks Ahead'] < 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "ito_verif_comp.loc[ito_verif_comp[f'Prophet Model up until {split_date}'] < 0.0, f'Prophet Model up until {split_date}'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, ax = plt.subplots(figsize=(25,8))\n",
    "ito_verif_comp.loc[:,['Observations',f'Prophet Model up until {split_date}'\\\n",
    "                  ,'Current Excel Model','Prophet Model Two Weeks Ahead']].plot(ax=ax)\n",
    "# ax.fill_between(verif_comp.index, verif_comp.loc[:,'yhat_lower'], verif_comp.loc[:,'yhat_upper'], color='coral', alpha=0.3)\n",
    "\n",
    "\n",
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(ito_verif_comp['Current Excel Model'] - ito_verif_comp['Observations'])/ito_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(ito_verif_comp[f'Prophet Model up until {split_date}'] - ito_verif_comp['Observations'])/ito_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(ito_verif_comp['Prophet Model Two Weeks Ahead'] - ito_verif_comp['Observations'])/ito_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(np.abs(ito_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - ito_verif_comp['Observations'].replace(0, np.nan))/ito_verif_comp['Observations'].replace(0, np.nan)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE TOP 3 OUTLIERS SKEWING MAPE RESULTS\n",
    "adj_ito_verif_comp = ito_verif_comp[~ito_verif_comp.index.isin(['2019-06-17','2019-07-02','2019-06-27'])]\n",
    "\n",
    "# RECALCULATE MAPE RESULTS w/o OUTLIERS\n",
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(adj_ito_verif_comp['Current Excel Model'].replace(0, np.nan) - adj_ito_verif_comp['Observations'].replace(0, np.nan))/adj_ito_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(adj_ito_verif_comp[f'Prophet Model up until {split_date}'].replace(0, np.nan) - adj_ito_verif_comp['Observations'].replace(0, np.nan))/adj_ito_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(adj_ito_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - adj_ito_verif_comp['Observations'].replace(0, np.nan))/adj_ito_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G. FB Prophet Model - Outbound Vendor Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vr_m = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           #,holidays = vr_holidays\n",
    "           )\n",
    "\n",
    "vr_m_full = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           #,holidays = vr_holidays\n",
    "           )\n",
    "\n",
    "# fit the model\n",
    "vr_m.fit(vr_dat_train)\n",
    "vr_m_full.fit(vr_dat_all)\n",
    "\n",
    "# predict forward_days \n",
    "vr_future = vr_m.make_future_dataframe(periods=len(vr_dat_test)+forward_days, freq='1D')\n",
    "vr_forecast = vr_m.predict(vr_future)\n",
    "vr_forecast.loc[vr_forecast.ds>=split_date,:].head()\n",
    "\n",
    "# components showing\n",
    "vr_m_full.component_modes\n",
    "\n",
    "## Validation\n",
    "fig = vr_m.plot(vr_forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), vr_m, vr_forecast)\n",
    "\n",
    "\n",
    "f = vr_m.plot_components(vr_forecast)\n",
    "\n",
    "\n",
    "vr_verif = utils.make_verif(vr_forecast, vr_dat_train, vr_dat_test)\n",
    "f = utils.plot_verif(vr_verif,date=split_date)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(vr_verif, '2019-01-01', '2019-12-31', ax=ax)\n",
    "\n",
    "\n",
    "utils.plot_joint_plot(vr_verif.loc[vr_verif.index<split_date,:], title='train set', fname=None)\n",
    "\n",
    "utils.plot_joint_plot(vr_verif.loc[(vr_verif.index>=split_date) &(vr_verif['y'].notnull()) ,:], \\\n",
    "                      title='test set', fname=None)\n",
    "\n",
    "## Cross Validation\n",
    "df_cv = cross_validation(vr_m_full, initial='1210 days', period='7 days', horizon = '14 days')\n",
    "df_cv_two_week = cross_validation(vr_m_full, initial='1210 days', period='1 days', horizon = '14 days')\n",
    "\n",
    "df_cv['horizon'] = df_cv['ds']  - df_cv['cutoff']\n",
    "df_cv['mape'] = np.abs(df_cv['yhat'] - df_cv['y'])/ df_cv['y']\n",
    "df_cv = df_cv.loc[df_cv.mape<1,:]\n",
    "df_p = performance_metrics(df_cv, rolling_window=0.1)\n",
    "df_p.head()\n",
    "\n",
    "df_cv_two_week['horizon'] = df_cv_two_week['ds']  - df_cv_two_week['cutoff']\n",
    "df_two_week_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='14 days',:]\n",
    "df_two_week_prediction.index = df_two_week_prediction.ds\n",
    "df_two_week_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "df_1_day_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='1 days',:]\n",
    "df_1_day_prediction.index = df_1_day_prediction[\"ds\"]\n",
    "df_1_day_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vr_verif_comp = pd.concat([vr_verif], axis=1, join='inner').\\\n",
    "filter(items=['yhat_lower','yhat_upper','yhat','y','excel_forecast'])\n",
    "vr_verif_comp = vr_verif_comp.loc[vr_verif_comp['y'].notnull() ,:]\n",
    "vr_verif_comp.rename(columns ={'y':'Observations' , 'yhat':f'Prophet Model up until {split_date}'} ,inplace=True)\n",
    "\n",
    "vr_verif_comp = vr_verif_comp.merge(right = df_two_week_prediction, on=\"ds\" ,how = \"inner\", suffixes=('',\"_2w\"))\n",
    "vr_verif_comp.rename(columns ={'yhat':'Prophet Model Two Weeks Ahead'} ,inplace=True)\n",
    "\n",
    "# if weekend then make it 0\n",
    "vr_verif_comp['weekend'] = ((pd.DatetimeIndex(vr_verif_comp.index).dayofweek) // 5 == 1).astype(float)\n",
    "vr_verif_comp.loc[vr_verif_comp['weekend'] > 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "vr_verif_comp.loc[vr_verif_comp['weekend'] > 0.0, f'Prophet Model up until {split_date}'] = 0\n",
    "\n",
    "# if negative then make it 0\n",
    "vr_verif_comp.loc[vr_verif_comp['Prophet Model Two Weeks Ahead'] < 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "vr_verif_comp.loc[vr_verif_comp[f'Prophet Model up until {split_date}'] < 0.0, f'Prophet Model up until {split_date}'] = 0\n",
    "\n",
    "#verif_comp.head()\n",
    "\n",
    "_, ax = plt.subplots(figsize=(25,8))\n",
    "vr_verif_comp.loc[:,['Observations',f'Prophet Model up until {split_date}'\\\n",
    "                  ,'Prophet Model Two Weeks Ahead']].plot(ax=ax)\n",
    "# ax.fill_between(verif_comp.index, verif_comp.loc[:,'yhat_lower'], verif_comp.loc[:,'yhat_upper'], color='coral', alpha=0.3)\n",
    "\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(vr_verif_comp[f'Prophet Model up until {split_date}'] - vr_verif_comp['Observations'])/vr_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(vr_verif_comp['Prophet Model Two Weeks Ahead'] - vr_verif_comp['Observations'])/vr_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(np.abs(vr_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - vr_verif_comp['Observations'].replace(0, np.nan))/vr_verif_comp['Observations'].replace(0, np.nan)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE TOP 3 OUTLIERS SKEWING MAPE RESULTS\n",
    "adj_vr_verif_comp = vr_verif_comp[~vr_verif_comp.index.isin(['2019-06-04','2019-06-11','2019-05-22'])]\n",
    "\n",
    "# RECALCULATE MAPE RESULTS w/o OUTLIERS\n",
    "#print('MAPE of the Current Model ' + str(np.mean(np.abs(adj_vr_verif_comp['Current Excel Model'].replace(0, np.nan) - adj_vr_verif_comp['Observations'].replace(0, np.nan))/adj_vr_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(adj_vr_verif_comp[f'Prophet Model up until {split_date}'].replace(0, np.nan) - adj_vr_verif_comp['Observations'].replace(0, np.nan))/adj_vr_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(adj_vr_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - adj_vr_verif_comp['Observations'].replace(0, np.nan))/adj_vr_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H. FB Prophet Model - Outbound Transfer Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oto_m = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           #,holidays = oto_holidays\n",
    "           )\n",
    "\n",
    "oto_m_full = Prophet(changepoint_prior_scale=0.1, changepoint_range=0.9 ,\\\n",
    "            seasonality_mode='multiplicative', seasonality_prior_scale = 10 ,\\\n",
    "            holidays_prior_scale = 10, \\\n",
    "            yearly_seasonality=True, \\\n",
    "            weekly_seasonality=True, \\\n",
    "            daily_seasonality=False \\\n",
    "           #,holidays = oto_holidays\n",
    "           )\n",
    "\n",
    "# fit the model\n",
    "oto_m.fit(oto_dat_train)\n",
    "oto_m_full.fit(oto_dat_all)\n",
    "\n",
    "# predict forward_days \n",
    "oto_future = oto_m.make_future_dataframe(periods=len(oto_dat_test)+forward_days, freq='1D')\n",
    "oto_forecast = oto_m.predict(oto_future)\n",
    "oto_forecast.loc[oto_forecast.ds>=split_date,:].head()\n",
    "\n",
    "# components showing\n",
    "oto_m_full.component_modes\n",
    "\n",
    "## Validation\n",
    "fig = oto_m.plot(oto_forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), oto_m, oto_forecast)\n",
    "\n",
    "\n",
    "f = oto_m.plot_components(oto_forecast)\n",
    "\n",
    "\n",
    "oto_verif = utils.make_verif(oto_forecast, oto_dat_train, oto_dat_test)\n",
    "f = utils.plot_verif(oto_verif,date=split_date)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, figsize=(16,10), sharey=True)\n",
    "utils.make_plot_block(oto_verif, '2019-01-01', '2019-12-31', ax=ax)\n",
    "\n",
    "\n",
    "utils.plot_joint_plot(oto_verif.loc[oto_verif.index<split_date,:], title='train set', fname=None)\n",
    "\n",
    "utils.plot_joint_plot(oto_verif.loc[(oto_verif.index>=split_date) &(oto_verif['y'].notnull()) ,:], \\\n",
    "                      title='test set', fname=None)\n",
    "\n",
    "## Cross Validation\n",
    "df_cv = cross_validation(oto_m_full, initial='1210 days', period='7 days', horizon = '14 days')\n",
    "df_cv_two_week = cross_validation(oto_m_full, initial='1210 days', period='1 days', horizon = '14 days')\n",
    "\n",
    "df_cv['horizon'] = df_cv['ds']  - df_cv['cutoff']\n",
    "df_cv['mape'] = np.abs(df_cv['yhat'] - df_cv['y'])/ df_cv['y']\n",
    "df_cv = df_cv.loc[df_cv.mape<1,:]\n",
    "df_p = performance_metrics(df_cv, rolling_window=0.1)\n",
    "df_p.head()\n",
    "\n",
    "df_cv_two_week['horizon'] = df_cv_two_week['ds']  - df_cv_two_week['cutoff']\n",
    "df_two_week_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='14 days',:]\n",
    "df_two_week_prediction.index = df_two_week_prediction.ds\n",
    "df_two_week_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "df_1_day_prediction = df_cv_two_week.loc[df_cv_two_week.horizon=='1 days',:]\n",
    "df_1_day_prediction.index = df_1_day_prediction[\"ds\"]\n",
    "df_1_day_prediction.drop(columns=\"ds\", inplace=True)\n",
    "\n",
    "oto_verif_comp = pd.concat([oto_dat_curr_prediction, oto_verif], axis=1, join='inner').\\\n",
    "filter(items=['yhat_lower','yhat_upper','yhat','y','excel_forecast'])\n",
    "oto_verif_comp = oto_verif_comp.loc[oto_verif_comp['y'].notnull() ,:]\n",
    "oto_verif_comp.rename(columns ={'y':'Observations' , 'yhat':f'Prophet Model up until {split_date}', 'excel_forecast':'Current Excel Model'} ,inplace=True)\n",
    "\n",
    "oto_verif_comp = oto_verif_comp.merge(right = df_two_week_prediction, on=\"ds\" ,how = \"inner\", suffixes=('',\"_2w\"))\n",
    "oto_verif_comp.rename(columns ={'yhat':'Prophet Model Two Weeks Ahead'} ,inplace=True)\n",
    "\n",
    "# if weekend then make it 0\n",
    "oto_verif_comp['weekend'] = ((pd.DatetimeIndex(oto_verif_comp.index).dayofweek) // 5 == 1).astype(float)\n",
    "oto_verif_comp.loc[oto_verif_comp['weekend'] > 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "oto_verif_comp.loc[oto_verif_comp['weekend'] > 0.0, f'Prophet Model up until {split_date}'] = 0\n",
    "\n",
    "# if negative then make it 0\n",
    "oto_verif_comp.loc[oto_verif_comp['Prophet Model Two Weeks Ahead'] < 0.0, 'Prophet Model Two Weeks Ahead'] = 0\n",
    "oto_verif_comp.loc[oto_verif_comp[f'Prophet Model up until {split_date}'] < 0.0, f'Prophet Model up until {split_date}'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, ax = plt.subplots(figsize=(25,8))\n",
    "oto_verif_comp.loc[:,['Observations',f'Prophet Model up until {split_date}'\\\n",
    "                  ,'Current Excel Model','Prophet Model Two Weeks Ahead']].plot(ax=ax)\n",
    "# ax.fill_between(verif_comp.index, verif_comp.loc[:,'yhat_lower'], verif_comp.loc[:,'yhat_upper'], color='coral', alpha=0.3)\n",
    "\n",
    "\n",
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(oto_verif_comp['Current Excel Model'].replace(0, np.nan) - oto_verif_comp['Observations'].replace(0, np.nan))/oto_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(oto_verif_comp[f'Prophet Model up until {split_date}'].replace(0, np.nan) - oto_verif_comp['Observations'].replace(0, np.nan))/oto_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(oto_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - oto_verif_comp['Observations'].replace(0, np.nan))/oto_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(np.abs(oto_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - oto_verif_comp['Observations'].replace(0, np.nan))/oto_verif_comp['Observations'].replace(0, np.nan)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE TOP 3 OUTLIERS SKEWING MAPE RESULTS\n",
    "adj_oto_verif_comp = oto_verif_comp[~oto_verif_comp.index.isin(['2019-06-27','2019-06-07','2019-06-04'])]\n",
    "\n",
    "# RECALCULATE MAPE RESULTS w/o OUTLIERS\n",
    "print('MAPE of the Current Model ' + str(np.mean(np.abs(adj_oto_verif_comp['Current Excel Model'].replace(0, np.nan) - adj_oto_verif_comp['Observations'].replace(0, np.nan))/adj_oto_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Up Until {split_date}  ' + str(np.mean(np.abs(adj_oto_verif_comp[f'Prophet Model up until {split_date}'].replace(0, np.nan) - adj_oto_verif_comp['Observations'].replace(0, np.nan))/adj_oto_verif_comp['Observations'].replace(0, np.nan))))\n",
    "print(f'MAPE of the Prophet Model Two Weeks Prediction  ' + str(np.mean(np.abs(adj_oto_verif_comp['Prophet Model Two Weeks Ahead'].replace(0, np.nan) - adj_oto_verif_comp['Observations'].replace(0, np.nan))/adj_oto_verif_comp['Observations'].replace(0, np.nan))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --FINAL FB Prophet Ensemble Outputs--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_forecast.loc[ co_forecast['yhat'] < 0.0, 'yhat'] = 0\n",
    "po_forecast.loc[ po_forecast['yhat'] < 0.0, 'yhat'] = 0\n",
    "cr_forecast.loc[ cr_forecast['yhat'] < 0.0, 'yhat'] = 0\n",
    "ito_forecast.loc[ito_forecast['yhat'] < 0.0, 'yhat'] = 0\n",
    "oto_forecast.loc[oto_forecast['yhat'] < 0.0, 'yhat'] = 0\n",
    "vr_forecast.loc[ vr_forecast['yhat'] < 0.0, 'yhat'] = 0\n",
    "\n",
    "co_ensemble  =  co_forecast[['ds','yhat']]\n",
    "po_ensemble  =  po_forecast[['ds','yhat']]\n",
    "cr_ensemble  =  cr_forecast[['ds','yhat']]\n",
    "ito_ensemble = ito_forecast[['ds','yhat']]\n",
    "oto_ensemble = oto_forecast[['ds','yhat']]\n",
    "vr_ensemble  =  vr_forecast[['ds','yhat']]\n",
    "\n",
    "co_ensemble.rename(columns  ={'ds':'date_est','yhat':'fcst_out_co'} ,inplace=True)  \n",
    "po_ensemble.rename(columns  ={'yhat':'fcst_in_po'} ,inplace=True)   \n",
    "cr_ensemble.rename(columns  ={'yhat':'fcst_in_cr'} ,inplace=True)   \n",
    "ito_ensemble.rename(columns ={'yhat':'fcst_in_ito'} ,inplace=True)  \n",
    "oto_ensemble.rename(columns ={'yhat':'fcst_out_oto'} ,inplace=True)  \n",
    "vr_ensemble.rename(columns  ={'yhat':'fcst_out_vr'} ,inplace=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join outputs\n",
    "\n",
    "\n",
    "dfs = [co_ensemble[['date_est','fcst_out_co']] \\\n",
    "      ,po_ensemble[['ds','fcst_in_po']] \\\n",
    "      ,cr_ensemble[['ds','fcst_in_cr']] \\\n",
    "      ,ito_ensemble[['ds','fcst_in_ito']] \\\n",
    "      ,oto_ensemble[['ds','fcst_out_oto']] \\\n",
    "      ,vr_ensemble[['ds','fcst_out_vr']]] \n",
    "nan_value = 0\n",
    "\n",
    "fcst_ensemble = pd.concat(dfs, join='outer', axis=1).fillna(nan_value)\n",
    "fcst_ensemble.drop(columns=['ds'], inplace = True)\n",
    "\n",
    "\n",
    "#create total columns\n",
    "fcst_ensemble['fcst_total_ins'] =    fcst_ensemble['fcst_in_cr'] \\\n",
    "                                   + fcst_ensemble['fcst_in_po'] \\\n",
    "                                   + fcst_ensemble['fcst_in_ito']\n",
    "\n",
    "fcst_ensemble['fcst_total_outs'] =   fcst_ensemble['fcst_out_co'] \\\n",
    "                                   + fcst_ensemble['fcst_out_oto'] \\\n",
    "                                   + fcst_ensemble['fcst_out_vr'] \\\n",
    "\n",
    "fcst_ensemble['fcst_total_flow'] =   fcst_ensemble['fcst_out_co'] \\\n",
    "                                   + fcst_ensemble['fcst_out_oto'] \\\n",
    "                                   + fcst_ensemble['fcst_out_vr'] \\\n",
    "                                   + fcst_ensemble['fcst_in_cr'] \\\n",
    "                                   + fcst_ensemble['fcst_in_po'] \\\n",
    "                                   + fcst_ensemble['fcst_in_ito']\n",
    "\n",
    "fcst_ensemble['fcst_total_flow_adj'] = fcst_ensemble['fcst_out_co'] \\\n",
    "                                   + fcst_ensemble['fcst_out_oto'] \\\n",
    "                                   + fcst_ensemble['fcst_in_cr'] \\\n",
    "                                   + fcst_ensemble['fcst_in_po'] \\\n",
    "                                   + fcst_ensemble['fcst_in_ito'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fcst_ensemble.head())\n",
    "display(fcst_ensemble.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actuals  = data_raw_all.loc[data_raw_all.date_est>=split_date , :]\n",
    "test_forecast = fcst_ensemble.loc[fcst_ensemble.date_est>=split_date , :]\n",
    "\n",
    "test_actuals  = test_actuals.loc[test_actuals.date_est<='2019-07-23' , :]\n",
    "test_forecast = test_forecast.loc[test_forecast.date_est<='2019-07-23' , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_excel    = dat_curr_prediction.loc[dat_curr_prediction.FCST_Dt>=split_date , :]\n",
    "test_excel    = test_excel.loc[test_excel.FCST_Dt<='2019-07-23' , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actuals_exc_adj = test_actuals\n",
    "test_actuals_exc_adj['ADJ_TTL_ALL_UNITS'] = test_actuals['TTL_ALL_UNITS'] - test_actuals['OUT_VR_UNITS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_actuals = test_actuals.reset_index(drop=True)\n",
    "test_forecast = test_forecast.reset_index(drop=True)\n",
    "test_actuals_exc_adj = test_actuals_exc_adj.reset_index(drop=True)\n",
    "\n",
    "display(test_actuals.head())\n",
    "display(test_excel.head())\n",
    "display(test_actuals_exc_adj.head())\n",
    "display(test_forecast.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MAPE of the Prophet Model ' \\\n",
    "      + str(np.mean(np.abs(test_forecast['fcst_total_flow'] \\\n",
    "      - test_actuals['TTL_ALL_UNITS']) \\\n",
    "      / test_actuals['TTL_ALL_UNITS'])))\n",
    "\n",
    "print(f'MAE of the Prophet Model ' \\\n",
    "      + str(np.mean(np.abs(test_forecast['fcst_total_flow'] \\\n",
    "      - test_actuals['TTL_ALL_UNITS']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MAPE of the Prophet Model ' \\\n",
    "      + str(np.mean(np.abs(test_forecast['fcst_total_outs'] \\\n",
    "      - test_actuals['TTL_OUT_UNITS']) \\\n",
    "      / test_actuals['TTL_OUT_UNITS'])))\n",
    "\n",
    "print(f'MAE of the Prophet Model ' \\\n",
    "      + str(np.mean(np.abs(test_forecast['fcst_total_outs'] \\\n",
    "      - test_actuals['TTL_OUT_UNITS']))))\n",
    "\n",
    "\n",
    "print(f'MAPE of the Prophet Model ' \\\n",
    "      + str(np.mean(np.abs(test_forecast['fcst_total_ins'].replace(0, np.nan) \\\n",
    "      - test_actuals['TTL_IN_UNITS'].replace(0, np.nan)) \\\n",
    "      / test_actuals['TTL_IN_UNITS'].replace(0, np.nan))))\n",
    "\n",
    "print(f'MAE of the Prophet Model ' \\\n",
    "      + str(np.mean(np.abs(test_forecast['fcst_total_ins'] \\\n",
    "      - test_actuals['TTL_IN_UNITS']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MAPE of the Excel Model ' \\\n",
    "      + str(np.mean(np.abs(test_excel['FCT_TOTAL'] \\\n",
    "      - test_actuals_exc_adj['ADJ_TTL_ALL_UNITS']) \\\n",
    "      / test_actuals_exc_adj['ADJ_TTL_ALL_UNITS'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MAPE of the Prophet Model ' \\\n",
    "      + str(np.mean(np.abs(test_forecast['fcst_total_flow_adj'] \\\n",
    "      - test_actuals_exc_adj['ADJ_TTL_ALL_UNITS']) \\\n",
    "      / test_actuals_exc_adj['ADJ_TTL_ALL_UNITS'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fcst_ensemble.head())\n",
    "display(fcst_ensemble.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data to bigquery\n",
    "fcst_ensemble.to_gbq('adhoc_analytics.temp_test_py2bq',project_id='moda-operandi-dw',if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
